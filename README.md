<div align="center">
  <h1>Lucid A2UI</h1>
  <p>
    <strong>The Last Mile from AI to Human</strong>
  </p>
  <p>
    AI-to-UI Intermediate Representation (IR) Protocol Layer
  </p>

  <p>
    <a href="https://github.com/Deepractice/Lucid-UI"><img src="https://img.shields.io/github/stars/Deepractice/Lucid-UI?style=social" alt="Stars"/></a>
    <img src="https://komarev.com/ghpvc/?username=LucidUI&label=views&color=0e75b6&style=flat&abbreviated=true" alt="Views"/>
    <a href="LICENSE"><img src="https://img.shields.io/github/license/Deepractice/Lucid-UI?color=blue" alt="License"/></a>
    <a href="https://www.npmjs.com/package/@lucidui/react"><img src="https://img.shields.io/npm/v/@lucidui/react?color=cb3837&logo=npm" alt="npm"/></a>
  </p>

  <p>
    <a href="README.md"><strong>English</strong></a> |
    <a href="README.zh-CN.md">ç®€ä½“ä¸­æ–‡</a>
  </p>
</div>

---

## The Last Mile Problem

```
Human Intent â†’ AI Understanding â†’ AI Generation â†’ ??? â†’ Human Perception
                                                   â†‘
                                            The gap is here
```

AI can understand human intent, reason, call tools, and generate content. But **how does AI output actually reach the human?** This "last mile" has been broken.

**Lucid A2UI bridges this gap** â€” a protocol that both AI and UI understand.

---

## What is Lucid A2UI?

**Lucid A2UI** is an Intermediate Representation (IR) protocol layer between AI and UI.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Lucid A2UI                             â”‚
â”‚           "The Last Mile from AI to Human"                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Human Intent                                               â”‚
â”‚       â†“                                                     â”‚
â”‚  AI Processing (thinking, tool calls, generation)           â”‚
â”‚       â†“                                                     â”‚
â”‚  Lucid IR â† Standardized format AI outputs                  â”‚
â”‚       â†“                                                     â”‚
â”‚  UI Rendering â† Components that understand IR               â”‚
â”‚       â†“                                                     â”‚
â”‚  Human Perception                                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Two Consumers, One Protocol

> **Lucid IR is consumed by both AI and UI.**

- **For AI**: A standardized output format â€” AI generates Lucid IR directly
- **For UI**: A standardized input format â€” UI renders Lucid IR directly
- **Result**: AI speaks this format, UI understands this format â€” no translation needed

---

## Why Lucid A2UI?

### The Problem

| Protocol | Status | Issue |
|----------|--------|-------|
| A2UI (Google) | v0.8 Preview | Only Android TV/Wear OS, **no Web** |
| MCP Apps (Anthropic) | SEP-1865 Draft | Still in design, **not usable** |

**No production-ready AI-to-UI protocol exists today.**

### The Solution

Lucid UI provides:
1. **Lucid IR** - A stable internal protocol that works today
2. **Adapters** - Future compatibility with A2UI, MCP Apps when they mature
3. **Reference implementation** - React renderer as default

```
AI Agent Events
    â†“
Lucid IR (stable internal protocol)
    â†“
    â”œâ”€â”€ ReactRenderer (works today)
    â”œâ”€â”€ A2UIRenderer (when A2UI matures)
    â””â”€â”€ MCPAppsRenderer (when MCP Apps matures)
```

---

## Lucid IR vs Design Tokens

> **"Design Tokens let developers stop redefining colors. Lucid IR lets AI stop relearning how to describe UI structure."**

### Different Layers, Different Problems

```
Lucid IR       = Script (what to perform)
React Components = Actors (how to perform)
Design Tokens  = Costumes & Props (what to wear)
```

| Dimension | Design Tokens | Lucid IR |
|-----------|---------------|----------|
| Problem Solved | Design-to-code consistency | AI-output-to-UI standardization |
| Consumer | Human developers (understands CSS) | AI (needs structured, semantic description) |
| Target Market | Design systems, component libraries | AI Agent platforms |
| Competitors | Style Dictionary, Theo | None (greenfield market) |

### The Key Insight

Traditional UI pipeline:
```
Designer (Figma) â†’ Developer writes code â†’ User sees UI
                   â†‘ Design Tokens solve this
```

AI Agent pipeline:
```
AI reasoning â†’ Lucid IR â†’ Renderer â†’ User sees UI
               â†‘ Lucid IR solves this (no one did before)
```

**Design Tokens is "style variables". Lucid IR is "AI's UI expression language"** â€” completely different layers and purposes.

---

## Architecture

### Three-Layer Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Lucid IR (Core)                                   â”‚
â”‚  - JSON Schema definition                                   â”‚
â”‚  - Block & Conversation standards                           â”‚
â”‚  - AI-generatable format                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Renderers                                         â”‚
â”‚  - ReactRenderer â†’ Web                                      â”‚
â”‚  - A2UIRenderer â†’ Native (future)                           â”‚
â”‚  - MCPAppsRenderer â†’ Claude Desktop (future)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Design System                                     â”‚
â”‚  - @lucidui/tokens (design tokens)                          â”‚
â”‚  - @lucidui/react (base components)                         â”‚
â”‚  - @lucidui/stream (streaming renderer)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Inversion

All implementations depend on the Lucid IR abstraction:

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Lucid IR        â”‚  â† Abstract protocol
        â”‚   (JSON Schema)     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚             â”‚             â”‚
     â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AgentX  â”‚  â”‚  Other   â”‚  â”‚  A2UI    â”‚
â”‚   UI    â”‚  â”‚Frameworksâ”‚  â”‚ Adapter  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Lucid IR Specification

### Core Types

```typescript
interface LucidConversation {
  id: string
  role: 'user' | 'assistant' | 'system'
  status: 'streaming' | 'completed' | 'error'
  blocks: LucidBlock[]
  timestamp: number
}

interface LucidBlock {
  id: string
  type: 'text' | 'tool' | 'thinking' | 'image' | 'file' | 'error'
  status: 'streaming' | 'completed' | 'error'
  content: unknown  // varies by type
}

// Renderer interface
interface LucidRenderer<T> {
  render(conversations: LucidConversation[]): T
}
```

### Block Types

| Type | Description | Content |
|------|-------------|---------|
| `text` | Text content (supports streaming) | `{ text: string }` |
| `tool` | Tool/function call result | `{ name, input, output, status }` |
| `thinking` | AI reasoning process | `{ reasoning: string }` |
| `image` | Image content | `{ url, alt, width, height }` |
| `file` | File attachment | `{ name, type, url }` |
| `error` | Error message | `{ code, message }` |

---

## Relationship with AgentX

Lucid UI is abstracted from [AgentX](https://github.com/Deepractice/AgentX) practices:

```
AgentX UI (rough implementation, experimental)
    â†“ abstract & refine
Lucid IR (protocol specification)
    â†“ implement
AgentX UI + Other frameworks (follow the spec)
```

### Event Flow

```
AgentX 4-Layer Events
    â”‚
    â”‚ Stream: text_delta, tool_use_start
    â”‚ State: conversation_thinking, tool_executing
    â”‚ Message: assistant_message, tool_result_message
    â”‚
    â†“ Transform
Lucid IR (LucidConversation[])
    â†“ Render
React Components
```

---

## Packages

| Package | Layer | Status | Description |
|---------|-------|--------|-------------|
| `@lucidui/ir` | Protocol | ğŸš§ Designing | Lucid IR JSON Schema & TypeScript types |
| `@lucidui/tokens` | Design System | âœ… Ready | Design tokens (colors, typography, spacing) |
| `@lucidui/react` | Renderer | âœ… Ready | React renderer & base components |
| `@lucidui/stream` | Renderer | ğŸš§ Building | Streaming content renderer |

---

## Quick Start

### For Developers (React Renderer)

```bash
pnpm add @lucidui/react @lucidui/tokens
```

```tsx
import { Button } from '@lucidui/react'

function App() {
  return <Button>Click me</Button>
}
```

### For AI Agents (Lucid IR)

```json
{
  "conversations": [
    {
      "id": "conv-1",
      "role": "user",
      "status": "completed",
      "blocks": [
        { "id": "b1", "type": "text", "status": "completed", "content": { "text": "Hello" } }
      ]
    },
    {
      "id": "conv-2",
      "role": "assistant",
      "status": "streaming",
      "blocks": [
        { "id": "b2", "type": "text", "status": "streaming", "content": { "text": "Hi there..." } },
        { "id": "b3", "type": "tool", "status": "completed", "content": { "name": "search", "output": "..." } }
      ]
    }
  ]
}
```

---

## Design Philosophy

### Dual Theme System

**Rational Theme** - Tech Blue `#0284c7`
- For: Data analysis, Technical products, Productivity tools
- Represents: Efficiency, Precision, Computation

**Sentient Theme** - Wisdom Gold `#f59e0b`
- For: Creative tools, Human-centric products, Thinking aids
- Represents: Wisdom, Thinking, Humanity

### Design Principles

1. **White Foundation** - Clear visual base, no dark mode
2. **No AI Purple** - Reject overused AI clichÃ©s
3. **Block-Based** - Parallel rendering of text + tools
4. **Streaming-First** - Self-healing incomplete content
5. **Accessibility by Default** - Not an afterthought

---

## Roadmap

### Phase 1: Foundation (Current)
- [x] Design token system
- [x] React base components
- [x] Streaming renderer
- [ ] Lucid IR schema definition

### Phase 2: Protocol
- [ ] Lucid IR JSON Schema
- [ ] TypeScript type definitions
- [ ] AgentX adapter
- [ ] Validation tools

### Phase 3: Ecosystem
- [ ] A2UI renderer (when mature)
- [ ] MCP Apps renderer (when mature)
- [ ] Documentation & examples

---

## Why Not Just Wait for A2UI / MCP Apps?

> "A2UI and MCP Apps are future targets. Lucid IR is today's bridge. We're not reinventing the wheelâ€”we're building an adapter that can fit any wheel."

| Approach | Risk |
|----------|------|
| Wait for standards | AgentX has no UI, product stalls |
| Bind to A2UI directly | A2UI changes, major rewrite needed |
| Bind to MCP Apps directly | Same problem |
| **Lucid IR + Adapters** | Internal stability, external flexibility |

---

## Ecosystem

Part of the **Deepractice AI development ecosystem**:

| Project | Description |
|---------|-------------|
| [AgentX](https://github.com/Deepractice/AgentX) | AI Agent development framework |
| [PromptX](https://github.com/Deepractice/PromptX) | Prompt engineering platform |
| [DPML](https://github.com/Deepractice/dpml) | Deepractice Markup Language |

---

## Development

```bash
git clone https://github.com/Deepractice/Lucid-UI.git
cd Lucid-UI
pnpm install
pnpm dev
```

---

## License

MIT - see [LICENSE](LICENSE)

---

<div align="center">
  <strong>Built with clarity by <a href="https://deepractice.ai">Deepractice</a></strong>
</div>
